{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from model import Model\n",
    "from clustering import adaptive_spectral_partition\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from typing import Sequence, List, Set\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import math\n",
    "from random import sample\n",
    "from scipy.io import savemat, loadmat\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vi(predicted_labels: Sequence[int],\n",
    "       true_labels: Sequence[int]) -> float:\n",
    "    def expand(labels: Sequence[int]) -> List[Set[int]]:\n",
    "        expanded = {label: set() for label in labels}\n",
    "        for node, label in enumerate(labels):\n",
    "            expanded[label].add(node)\n",
    "        return list(expanded.values())\n",
    "\n",
    "    n = len(predicted_labels)\n",
    "    predicted = expand(predicted_labels)\n",
    "    p = list(map(lambda x: len(x) / n, predicted))\n",
    "    true = expand(true_labels)\n",
    "    q = list(map(lambda x: len(x) / n, true))\n",
    "    r = [[len(predicted[i].intersection(true[j])) / n\n",
    "          for j in range(len(true))]\n",
    "         for i in range(len(predicted))]\n",
    "    vi = sum([r[i][j] * (np.log(r[i][j] / p[i]) + np.log(r[i][j] / q[j]))\n",
    "              if r[i][j] > 0 else 0\n",
    "              for j in range(len(true))\n",
    "              for i in range(len(predicted))]) * -1\n",
    "    return abs(vi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_cluster(labels):\n",
    "    num_clusters = len(set(labels))\n",
    "    v_hat = [set() for _ in range(num_clusters)]\n",
    "    for i, label in enumerate(labels):\n",
    "        v_hat[label].add(i)\n",
    "    return v_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_to_labeling(clusters):\n",
    "    labels = np.zeros(sum(map(len, clusters)), dtype=int)\n",
    "    for k, cluster in enumerate(clusters):\n",
    "        for v in cluster:\n",
    "            labels[v] = k\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "def edge_error_rate(predicted_v, true_v):\n",
    "    n = sum(map(len, true_v))\n",
    "    A_hat = np.zeros((n, n), dtype=int)\n",
    "    A = np.zeros((n, n), dtype=int)\n",
    "    for cluster in map(list, predicted_v):\n",
    "        for i, j in product(cluster, cluster):\n",
    "            A_hat[i, j] = 1\n",
    "    for cluster in map(list, true_v):\n",
    "        for i, j in product(cluster, cluster):\n",
    "            A[i, j] = 1\n",
    "    return (A_hat != A).sum() / (n * n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_conf = loadmat('../../mat/allSportsDataForMatlab.mat')['Pconf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true = loadmat('../../mat/all_sports_ground_truth.mat')['all_sports_ground_truth'][0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(p_conf)\n",
    "num_nodes_kernel = int(np.ceil(n / (5 * np.log(n))))\n",
    "\n",
    "v_hats = []\n",
    "v_hats_removed = []\n",
    "overflow_nodes = []\n",
    "\n",
    "T_s = []\n",
    "vi_s = []\n",
    "vi_no_over_s = []\n",
    "edge_err_s = []\n",
    "edge_err_no_over_s = []\n",
    "K_pred_s = []\n",
    "T_actual = []\n",
    "p_hats = []\n",
    "q_hats = []\n",
    "mean_T = []\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "alpha = [1 / 1 for _ in range(2)]\n",
    "model = Model(2, n, alpha)\n",
    "model.pair_prob_mat = p_conf\n",
    "T = 60000\n",
    "\n",
    "for it in range(10):\n",
    "    v_hat, overflow_nodes, T_remained, p_hat, q_hat, observed_times = adaptive_spectral_partition(T, num_nodes_kernel, model)\n",
    "\n",
    "    v_hat_overflow_removed = deepcopy(v_hat)\n",
    "    for v in overflow_nodes:\n",
    "        for cluster in v_hat_overflow_removed:\n",
    "            if v in cluster:\n",
    "                cluster.remove(v)\n",
    "\n",
    "    for v in overflow_nodes:\n",
    "        v_hat_overflow_removed[np.random.randint(len(v_hat))].add(v)\n",
    "\n",
    "    labels_hat = clustering_to_labeling(v_hat)\n",
    "    labels_hat_overflow_removed = clustering_to_labeling(v_hat_overflow_removed)\n",
    "\n",
    "    voi = vi(labels_hat, labels_true)\n",
    "    voi_overflow_removed = vi(labels_hat_overflow_removed, labels_true)\n",
    "\n",
    "    v_true = label_to_cluster(labels_true)\n",
    "    edge_err = edge_error_rate(v_hat, v_true)\n",
    "    edge_err_overflow_removed = edge_error_rate(v_hat_overflow_removed, v_true)\n",
    "\n",
    "    v_hats.append(list(map(list, v_hat)))\n",
    "    v_hats_removed.append(list(map(list, v_hat_overflow_removed)))\n",
    "    overflow_nodes.append(overflow_nodes)\n",
    "\n",
    "    K_predicted = len(v_hat)\n",
    "\n",
    "    T_s.append(T)\n",
    "    vi_s.append(voi)\n",
    "    p_hats.append(p_hat)\n",
    "    q_hats.append(q_hat)\n",
    "    vi_no_over_s.append(voi_overflow_removed)\n",
    "    edge_err_s.append(edge_err)\n",
    "    edge_err_no_over_s.append(edge_err_overflow_removed)\n",
    "    K_pred_s.append(K_predicted)\n",
    "    T_actual.append(np.abs(T_remained) + T)\n",
    "    mean_T.append(np.mean(list(observed_times.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "meta_data = {\n",
    "    'T': T_s,\n",
    "    'v_hats': v_hats,\n",
    "    'v_hats_removed': v_hats_removed,\n",
    "    'overflow_nodes': overflow_nodes\n",
    "}\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'T': T_s,\n",
    "    'VI': vi_s,\n",
    "    'VI_r': vi_no_over_s,\n",
    "    'p_hat': p_hats,\n",
    "    'q_hat': q_hats,\n",
    "    'edge_error_rate': edge_err_s,\n",
    "    'edge_error_rate_r': edge_err_no_over_s,\n",
    "    'K_predicted': K_pred_s,\n",
    "    'T_actual': T_actual,\n",
    "    'mean_T': mean_T\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50ed59304d9afbc1054070e7f5e28bcac6e732cc8b8985f0434243d498546bc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
